{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t02s5a0-qDws"
      },
      "source": [
        "### Connect to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhEs2DHNp5bu",
        "outputId": "779d1f45-1d1e-4b06-b4bd-e091ea0089af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive/[2023-2024] AN2DL/Homework2\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/[2023-2024] AN2DL/Homework2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om8KoBQQqOWH"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkbpp35sqQke",
        "outputId": "c75cca0e-0072-4496-9193-4e1a378fee50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "seed = 31\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
        "warnings.simplefilter(action = 'ignore', category = Warning)\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(seed)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "print(tf.__version__)\n",
        "\n",
        "#tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "import keras\n",
        "from keras.backend import sigmoid\n",
        "from keras.layers import Activation\n",
        "from keras.utils import get_custom_objects\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7JMt5Pyqbve"
      },
      "source": [
        "### Import Data from the ZIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FPk2uTJwqgEo"
      },
      "outputs": [],
      "source": [
        "unzip = False\n",
        "\n",
        "if unzip:\n",
        "\n",
        "    !unzip training_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KkdjbRfYpABZ"
      },
      "outputs": [],
      "source": [
        "#data loading\n",
        "data = np.load('training_data.npy')\n",
        "categories = np.load('categories.npy')\n",
        "validPeriods = np.load('valid_periods.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVQOLF-6p0r-",
        "outputId": "d705c42f-6e50-497d-fced-7ca431088fc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 2776), (48000,), (48000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "data.shape, categories.shape, validPeriods.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fbeRjr-VwdhG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0zEm0jbqgfD"
      },
      "source": [
        "### Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dy087VmdyI-P"
      },
      "outputs": [],
      "source": [
        "# Set a = True to remove the zeros\n",
        "#saves the starting position of each sequence in an array, then removes the padding in all sequences and saves them in \"dataNoPadding\"\n",
        "\n",
        "a = True\n",
        "\n",
        "if a:\n",
        "\n",
        "  startingIndexes = []\n",
        "\n",
        "  for element in validPeriods:\n",
        "\n",
        "    index = element[0]\n",
        "    startingIndexes.append(index)\n",
        "\n",
        "  dataNoPadding = np.array([series[index:] for series, index in zip(data, startingIndexes)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GyWWvIHeqjjY"
      },
      "outputs": [],
      "source": [
        "#extracts the specified cateogry out of the dataset\n",
        "def categoryExtractor (data, category):\n",
        "\n",
        "  pos = np.where(categories == category)\n",
        "  dataCat = data[pos]\n",
        "\n",
        "  return dataCat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTF2YOqRu0p2",
        "outputId": "feb84178-dafd-4bed-b6b3-969820444fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5728,) (10987,) (10017,) (10016,) (10975,) (277,)\n"
          ]
        }
      ],
      "source": [
        "A = categoryExtractor(dataNoPadding, 'A')\n",
        "B = categoryExtractor(dataNoPadding, 'B')\n",
        "C = categoryExtractor(dataNoPadding, 'C')\n",
        "D = categoryExtractor(dataNoPadding, 'D')\n",
        "E = categoryExtractor(dataNoPadding, 'E')\n",
        "F = categoryExtractor(dataNoPadding, 'F')\n",
        "\n",
        "print(A.shape, B.shape, C.shape, D.shape, E.shape, F.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "iYHkkARvC3Fj"
      },
      "outputs": [],
      "source": [
        "#returns the all the sequence lengths contained in data\n",
        "def countLen (data):\n",
        "\n",
        "  #counts the length of the sequence for each sequence in data\n",
        "  array_lengths = np.array([len(arr) for arr in data])\n",
        "\n",
        "  return np.sort(array_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UV4MXpnSEcMf"
      },
      "outputs": [],
      "source": [
        "categories = ['A', 'B', 'C', 'D', 'E', 'F']\n",
        "keys = []\n",
        "\n",
        "#for each category, save the sequence lengths for further inspection\n",
        "for el in categories:\n",
        "\n",
        "  array = locals()[el]\n",
        "  keys.append(countLen(array))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI1gAFpnIDoX",
        "outputId": "39673f68-cf16-432d-ff9d-280a099004df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 A\n",
            "count  5728.000000\n",
            "mean    278.180342\n",
            "std     109.290380\n",
            "min      46.000000\n",
            "25%     184.000000\n",
            "50%     288.000000\n",
            "75%     316.000000\n",
            "max    1943.000000\n",
            "                  B\n",
            "count  10987.000000\n",
            "mean     165.942842\n",
            "std      116.141928\n",
            "min       42.000000\n",
            "25%       56.000000\n",
            "50%      157.000000\n",
            "75%      219.000000\n",
            "max     1484.000000\n",
            "                  C\n",
            "count  10017.000000\n",
            "mean     208.146251\n",
            "std      146.289417\n",
            "min       42.000000\n",
            "25%       97.000000\n",
            "50%      204.000000\n",
            "75%      272.000000\n",
            "max     2708.000000\n",
            "                  D\n",
            "count  10016.000000\n",
            "mean     216.990915\n",
            "std      149.173953\n",
            "min       42.000000\n",
            "25%       52.000000\n",
            "50%      238.000000\n",
            "75%      288.000000\n",
            "max     2641.000000\n",
            "                  E\n",
            "count  10975.000000\n",
            "mean     163.046014\n",
            "std      127.992337\n",
            "min       42.000000\n",
            "25%       51.000000\n",
            "50%      119.000000\n",
            "75%      288.000000\n",
            "max     2776.000000\n",
            "                 F\n",
            "count   277.000000\n",
            "mean    194.830325\n",
            "std     153.410846\n",
            "min      24.000000\n",
            "25%      89.000000\n",
            "50%     172.000000\n",
            "75%     216.000000\n",
            "max    1068.000000\n"
          ]
        }
      ],
      "source": [
        "#inspects how the sequence lengths are distributed\n",
        "i = 0\n",
        "\n",
        "for el in categories:\n",
        "\n",
        "  df = pd.DataFrame({el: keys[i]})\n",
        "  print(df.describe())\n",
        "  i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iMM9OjzgplPK"
      },
      "outputs": [],
      "source": [
        "#removes short sequences using a custom filter\n",
        "def removeShortSequences(data, i):\n",
        "\n",
        "  a = 1\n",
        "\n",
        "  newData = []\n",
        "  df = pd.DataFrame({el: keys[i]})\n",
        "  description = df.describe()\n",
        "  firstQuartile = description.loc['25%']\n",
        "  firstQuartile = firstQuartile['F']\n",
        "\n",
        "  if firstQuartile > 100:\n",
        "\n",
        "    for i in range(len(data)):\n",
        "\n",
        "      if len(data[i]) >= 80:\n",
        "        newData.append(data[i])\n",
        "\n",
        "  else:\n",
        "\n",
        "    for i in range(len(data)):\n",
        "\n",
        "      if len(data[i]) > 40:                            # Related to category 'F' (see above its description)\n",
        "        newData.append(data[i])\n",
        "\n",
        "  return np.array(newData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3RxvcRxGzPQ",
        "outputId": "ed95794b-70b8-47de-ec92-0954973d1e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5682,) (10987,) (10017,) (10016,) (10975,) (259,)\n"
          ]
        }
      ],
      "source": [
        "#save the new sequence categories, with the short sequences removed\n",
        "newA = removeShortSequences(A, 0)\n",
        "newB = removeShortSequences(B, 1)\n",
        "newC = removeShortSequences(C, 2)\n",
        "newD = removeShortSequences(D, 3)\n",
        "newE = removeShortSequences(E, 4)\n",
        "newF = removeShortSequences(F, 5)\n",
        "\n",
        "print(newA.shape, newB.shape, newC.shape, newD.shape, newE.shape, newF.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "WxVp51o_u8MR"
      },
      "outputs": [],
      "source": [
        "a = np.concatenate( (newA, newB, newC, newD, newE, newF), axis = 0 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOIQGXXb5VQx"
      },
      "source": [
        "### Define the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xNb1GAgE5a4S"
      },
      "outputs": [],
      "source": [
        "#hyperparamrers\n",
        "window = 200\n",
        "stride = 5\n",
        "telescope = 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-a0hWY5xRs_-"
      },
      "outputs": [],
      "source": [
        "calls = [\n",
        "            tfk.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 12, restore_best_weights = True),\n",
        "\n",
        "            tfk.callbacks.ReduceLROnPlateau(monitor = 'val_loss', mode = 'min', patience = 8, factor = 0.1, min_lr = 1e-5)\n",
        "      ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HJP9sgm2cXg"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "jcqdPJJ_46fQ",
        "outputId": "ce4f58b1-8249-47a5-e576-bd5dbe71681c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nFORWARD PADDING\\n\\n    lastValue = tempX[-1]\\n\\n    padding = np.full((paddingLen, tempX.shape[1]), lastValue, dtype='float32')\\n\\n    tempX = np.concatenate((tempX, padding))\\n    tempY = np.concatenate((tempY, padding))\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# creates sequences and performs padding\n",
        "\n",
        "flag = False                                              # flag = False for zero padding, flag = True for forward padding\n",
        "\n",
        "def createSeq (data, window, stride, telescope):\n",
        "\n",
        "  assert window % stride == 0\n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "  tempX = tempY = data.copy().values\n",
        "\n",
        "  #checks if the data is perfectly divided by the window\n",
        "  paddingCheck = len(data) % window\n",
        "\n",
        "  if(paddingCheck != 0):\n",
        "    #padds the sequence such that the window can be applied to the data an integer amount of times\n",
        "    paddingLen = window - len(data) % window\n",
        "\n",
        "    if flag: #forward padding\n",
        "\n",
        "      lastValue = tempX[-1]\n",
        "\n",
        "      padding = np.full((paddingLen, tempX.shape[1]), lastValue, dtype = 'float32')\n",
        "\n",
        "      tempX = np.concatenate((tempX, padding))\n",
        "      tempY = np.concatenate((tempY, padding))\n",
        "\n",
        "    else: #zero padding\n",
        "\n",
        "      padding = np.zeros((paddingLen, tempX.shape[1]), dtype = 'float32')\n",
        "      tempX = np.concatenate((padding, data))\n",
        "\n",
        "      padding = np.zeros((paddingLen,tempY.shape[1]), dtype = 'float32')\n",
        "      tempY = np.concatenate((padding,tempY))\n",
        "\n",
        "    assert len(tempX) % window == 0 #sanity check\n",
        "\n",
        "  for index in np.arange(0, len(tempX) - window - telescope, stride):\n",
        "\n",
        "    x.append(tempX[index: index + window])\n",
        "    y.append(tempY[index + window: index + window + telescope])\n",
        "\n",
        "  x = x\n",
        "  y = y\n",
        "\n",
        "  return np.array(x), np.array(y)\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "MEAN PADDING\n",
        "\n",
        "    mean_value = np.mean(data.values)\n",
        "\n",
        "    padding = np.full((paddingLen, tempX.shape[1]), mean_value, dtype='float32')\n",
        "    tempX = np.concatenate((padding, data))\n",
        "\n",
        "    padding = np.full((paddingLen, tempX.shape[1]), mean_value, dtype='float32')\n",
        "    tempY = np.concatenate((padding,tempY))\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "ZERO PADDING\n",
        "\n",
        "    padding = np.zeros((paddingLen, tempX.shape[1]), dtype = 'float32')\n",
        "    tempX = np.concatenate((padding, data))\n",
        "\n",
        "    padding = np.zeros((paddingLen,tempY.shape[1]), dtype = 'float32')\n",
        "    tempY = np.concatenate((padding,tempY))\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "BACKWARD PADDING\n",
        "\n",
        "    firstValue = tempX[0]\n",
        "\n",
        "    padding = np.full((paddingLen, tempX.shape[1]), firstValue, dtype='float32')\n",
        "\n",
        "    tempX = np.concatenate((padding, tempX))\n",
        "    tempY = np.concatenate((padding, tempY))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "FORWARD PADDING\n",
        "\n",
        "    lastValue = tempX[-1]\n",
        "\n",
        "    padding = np.full((paddingLen, tempX.shape[1]), lastValue, dtype='float32')\n",
        "\n",
        "    tempX = np.concatenate((tempX, padding))\n",
        "    tempY = np.concatenate((tempY, padding))\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "GdSFoKTu6zNS"
      },
      "outputs": [],
      "source": [
        "#loads sequenes one by one and inputs them in createseq (block 1, see below)\n",
        "def createSequences (data, window, stride, telescope):\n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "\n",
        "  for el in data:\n",
        "\n",
        "    #loads sequence\n",
        "    d = pd.DataFrame({'A': el})\n",
        "    xTemp, yTemp = createSeq(d, window, stride, telescope)\n",
        "\n",
        "    if(len(xTemp != 0)): #sanity check\n",
        "\n",
        "      x.append(xTemp)\n",
        "      y.append(yTemp)\n",
        "\n",
        "  x = np.concatenate( x, axis=0 )\n",
        "  y = np.concatenate( y, axis=0 )\n",
        "\n",
        "\n",
        "  return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "tdpJ6uDbVCSJ"
      },
      "outputs": [],
      "source": [
        "#standardization of values using robust scaler: this technique considers how\n",
        "#distant each data point is from the input’s median and,\n",
        "#specifically, it computes the distance by means of the Interquartile Range (IQR)\n",
        "\n",
        "def applyRobustScaler (data):\n",
        "\n",
        "  elements = []\n",
        "\n",
        "  for el in data:\n",
        "\n",
        "    scaler = RobustScaler()\n",
        "    reshaped = el.reshape(-1, 1)\n",
        "    scaled = scaler.fit_transform(reshaped)\n",
        "    normalized = reshaped.flatten()\n",
        "\n",
        "    elements.append(normalized)\n",
        "\n",
        "  return np.array(elements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "_PKauvlN3T5c"
      },
      "outputs": [],
      "source": [
        "# creates train and test set (block 2, see below)\n",
        "\n",
        "def createTrainTest (data):\n",
        "\n",
        "  flag = True                                           # flag = False for retraining with test set\n",
        "\n",
        "  testSize = round(len(data) * 0.1)\n",
        "\n",
        "  if flag:\n",
        "\n",
        "    xTest, yTest = createSequences(data[:testSize], window, stride, telescope)\n",
        "    xTrain, yTrain = createSequences(applyRobustScaler(data[testSize:]), window, stride, telescope)\n",
        "\n",
        "    print(testSize, len(data[:testSize]))\n",
        "\n",
        "  else:\n",
        "\n",
        "    xTest, yTest = createSequences(applyRobustScaler(data[:testSize]), window, stride, telescope)\n",
        "    xTrain, yTrain = createSequences(applyRobustScaler(data[testSize:]), window, stride, telescope)\n",
        "\n",
        "  return xTrain, yTrain, xTest, yTest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgri6_br5hrG",
        "outputId": "2c258b5b-a2a5-47c6-dad1-cea5641cad40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4794 4794\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((885907, 200, 1), (885907, 9, 1), (168722, 200, 1), (168722, 9, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "xTrainA, yTrainA, xTestA, yTestA = createTrainTest(a)\n",
        "\n",
        "xTrainA.shape, yTrainA.shape, xTestA.shape, yTestA.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08LbDDVT6U1R"
      },
      "source": [
        "### Define the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRZ1swDp-OeL"
      },
      "source": [
        "To train the model set the following parameters in the 'Load Data' Section:\n",
        "\n",
        "  - Block 1:\n",
        "             flag = True during the training of model with forward padding\n",
        "             flag = False during the training of the model with zero padding\n",
        "\n",
        "  - Block 2:\n",
        "  \n",
        "             flag = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf1Z_-mnP8Tc"
      },
      "outputs": [],
      "source": [
        "inputShape = xTrainA.shape[1:]\n",
        "outputShape = yTrainA.shape[1]\n",
        "batchSize = 128\n",
        "epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYQzHcmhHkft"
      },
      "outputs": [],
      "source": [
        "#model architecture\n",
        "\n",
        "def buildModel(input_shape, output_shape):\n",
        "\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    x = tfkl.LSTM(64, return_sequences = True, name='lstm')(input_layer)\n",
        "\n",
        "    cnn = tfkl.Conv1D(128,3,padding = 'same', activation = 'relu')(x)\n",
        "    cnn = tfkl.MaxPooling1D()(cnn)\n",
        "\n",
        "    cnn = tfkl.Conv1D(256,3,padding = 'same', activation = 'relu')(cnn)\n",
        "    cnn = tfkl.MaxPooling1D()(cnn)\n",
        "\n",
        "    cnn = tfkl.Conv1D(512,3,padding = 'same', activation = 'relu')(cnn)\n",
        "    gap = tfkl.GlobalAveragePooling1D()(cnn)\n",
        "\n",
        "    dropout = tfkl.Dropout(.25, seed = seed)(gap)\n",
        "\n",
        "    dense = tfkl.Dense(512, activation = tf.keras.activations.mish, kernel_constraint=tfk.constraints.MaxNorm(1.5))(dropout)\n",
        "\n",
        "    dropout = tfkl.Dropout(.1, seed = seed)(dense)\n",
        "\n",
        "    dense = tfkl.Dense(128, activation = tf.keras.activations.mish, kernel_constraint=tfk.constraints.MaxNorm(1.5))(dropout)\n",
        "\n",
        "    output_layer = tfkl.Dense(output_shape, activation = 'linear')(dense)\n",
        "\n",
        "    model = tf.keras.Model(inputs = input_layer, outputs = output_layer, name='LSTMCNN_Model')\n",
        "\n",
        "    model.compile(loss = tf.keras.losses.MeanSquaredError(), optimizer = tfk.optimizers.Nadam(learning_rate = 0.001, weight_decay=0.004, beta_1=0.9,\n",
        "                    beta_2=0.999, epsilon=1e-07, ema_momentum=0.99, name=\"Nadam\"), metrics = tf.keras.metrics.MeanAbsoluteError())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XIE36mAn8MH"
      },
      "outputs": [],
      "source": [
        "model = buildModel(inputShape, outputShape)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzZpRnOKoH6o"
      },
      "outputs": [],
      "source": [
        "#model training\n",
        "history = model.fit(\n",
        "\n",
        "    x = xTrainA,\n",
        "    y = yTrainA,\n",
        "    batch_size = batchSize,\n",
        "    epochs = epochs,\n",
        "    validation_split = .1,\n",
        "    callbacks = calls\n",
        "\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oshQXA9IoKgZ"
      },
      "outputs": [],
      "source": [
        "#plotting results\n",
        "\n",
        "best_epoch = np.argmin(history['val_loss'])\n",
        "plt.figure(figsize=(17,4))\n",
        "plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.title('Mean Squared Error')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(18,3))\n",
        "plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4bNP9CV8ETa"
      },
      "outputs": [],
      "source": [
        "model.save('ZeroPadding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnC2PoWM8CjA"
      },
      "outputs": [],
      "source": [
        "model.save('ForwardPadding')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsTdN5KM7svg"
      },
      "source": [
        "### Retrain with Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPcqUJ0o_3Te"
      },
      "source": [
        "To retrain the model considering also the test set, set the following parameters in the 'Load Data' Section:\n",
        "\n",
        "  - Block 1:\n",
        "             flag = True during the training of model with forward padding\n",
        "             flag = False during the training of the model with zero padding\n",
        "\n",
        "  - Block 2:\n",
        "  \n",
        "             flag = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqB0k3Jw7vmh"
      },
      "outputs": [],
      "source": [
        "#loads zero padding model\n",
        "model = tfk.models.load_model('ZeroPadding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZLFWScgwUtM"
      },
      "outputs": [],
      "source": [
        "#loads forward padding model\n",
        "model = tfk.models.load_model('ForwardPadding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZmIEGzp7zgO"
      },
      "outputs": [],
      "source": [
        "x = np.concatenate( (xTrainA, xTestA), axis=0 )\n",
        "y = np.concatenate( (yTrainA, yTestA), axis=0 )\n",
        "\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp_RrPXQ9Xda"
      },
      "outputs": [],
      "source": [
        "inputShape = x.shape[1:]\n",
        "outputShape = y.shape[1]\n",
        "batchSize = 128\n",
        "epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL9tHox-78yr"
      },
      "outputs": [],
      "source": [
        "#training with the whole dataset\n",
        "history = model.fit(\n",
        "\n",
        "    x = x,\n",
        "    y = y,\n",
        "    batch_size = batchSize,\n",
        "    epochs = 5,\n",
        "    validation_split = .1,\n",
        "    callbacks = calls\n",
        "\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE0MfrTL7-aB"
      },
      "outputs": [],
      "source": [
        "model.save('ZeroPaddingWithTest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUZEt7E68AMY"
      },
      "outputs": [],
      "source": [
        "model.save('ForwardPaddingWithTest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K06LLq9InE_"
      },
      "source": [
        "### Predict samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqVtDJLxoOa6"
      },
      "outputs": [],
      "source": [
        "#predictions and evaluations\n",
        "predictions = model.predict(xTestA, verbose = 0)\n",
        "\n",
        "print(f\"Predictions shape: {predictions.shape} \")\n",
        "\n",
        "mean_squared_error = tfk.metrics.mean_squared_error(yTestA.flatten(), predictions.flatten()).numpy()\n",
        "print(f\"Mean Squared Error: {mean_squared_error}\")\n",
        "\n",
        "mean_absolute_error = tfk.metrics.mean_absolute_error(yTestA.flatten(), predictions.flatten()).numpy()\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMXsRQ1ULFhU"
      },
      "source": [
        "### Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImPNWcR4LHWk"
      },
      "outputs": [],
      "source": [
        "#ensemble of zero padding and forward padding models\n",
        "models = []\n",
        "\n",
        "a = tfk.models.load_model('ZeroPaddingWithTest')\n",
        "b = tfk.models.load_model('ForwardPaddingWithTest')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO5Gjk0tLRl3"
      },
      "outputs": [],
      "source": [
        "a._name = \"ZeroPaddingWithTest\"\n",
        "b._name = \"ForwardPaddingWithTest\"\n",
        "\n",
        "\n",
        "models.append(a)\n",
        "models.append(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ4K3KK4qU9V"
      },
      "outputs": [],
      "source": [
        "#ensemble approach involving two models: one trained on the Zero Padding Dataset and another one trained on the\n",
        "#Forward Padding Dataset. We implemented a weighted average strategy, assigning a weight of 0.7 to the first\n",
        "#model and 0.3 to the second\n",
        "\n",
        "class WeightedSum(tfkl.Layer):\n",
        "\n",
        "    def __init__(self, a, **kwargs):\n",
        "        self.a = a\n",
        "        super(WeightedSum, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, model_outputs):\n",
        "        return self.a * model_outputs[0] + (1 - self.a) * model_outputs[1]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WVG-rWELVLQ"
      },
      "outputs": [],
      "source": [
        "def ensembleModels(models, model_input):\n",
        "\n",
        "    # collect outputs of models in a list\n",
        "    yModels = [model(model_input) for model in models]\n",
        "\n",
        "    # averaging outputs\n",
        "    yAvg = WeightedSum(0.7)([a(model_input), b(model_input)])\n",
        "\n",
        "    # build model from same input and avg output\n",
        "    ensembleModel = tfk.Model(inputs = model_input, outputs = yAvg, name = 'ensemble')\n",
        "\n",
        "    return ensembleModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05CfDtSGLWBA",
        "outputId": "2bb6d82f-2bc1-4161-e3b0-38ece01e2c1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"ensemble\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 200, 1)]             0         []                            \n",
            "                                                                                                  \n",
            " ZeroPaddingWithTest (Funct  (None, 18)                   864530    ['input_1[0][0]']             \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " ForwardPaddingWithTest (Fu  (None, 18)                   864530    ['input_1[0][0]']             \n",
            " nctional)                                                                                        \n",
            "                                                                                                  \n",
            " weighted_sum (WeightedSum)  (None, 18)                   0         ['ZeroPaddingWithTest[1][0]', \n",
            "                                                                     'ForwardPaddingWithTest[1][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1729060 (6.60 MB)\n",
            "Trainable params: 1729060 (6.60 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = tfk.Input(inputShape)\n",
        "modelEns = ensembleModels(models, inputs)\n",
        "modelEns.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ak9mC6yeNes"
      },
      "outputs": [],
      "source": [
        "modelEns.save('FinalEnsemble')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9j9R7iRKzAA"
      },
      "source": [
        "### Forecasting with 9 Steps Model (AutoRegressive)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de84dPj9Y2MN"
      },
      "outputs": [],
      "source": [
        "model = tfk.models.load_model('FinalEnsemble')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALiGFI6vZQwv"
      },
      "outputs": [],
      "source": [
        "firstPredictions = model.predict(xTestA, verbose = 0) #calculate predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hw0u0I9ibYWv"
      },
      "outputs": [],
      "source": [
        "#deletes the first 9 samples and adds our predictions\n",
        "newX = []\n",
        "\n",
        "i = 0\n",
        "\n",
        "for el in xTestA:\n",
        "\n",
        "  elWithoutNine = el[9:]\n",
        "  elWithPred = np.append(elWithoutNine, firstPredictions[i])\n",
        "\n",
        "  newX.append(elWithPred)\n",
        "  i += 1\n",
        "\n",
        "newX = np.array(newX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUce7BvphpzM"
      },
      "outputs": [],
      "source": [
        "newX = np.expand_dims(newX, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTeTIqaPc-0O"
      },
      "outputs": [],
      "source": [
        "#computes the second set of predictions\n",
        "SecondPredictions = model.predict(newX, verbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbx9LZ4vedMq"
      },
      "outputs": [],
      "source": [
        "#merges the two predictions\n",
        "pred = []\n",
        "\n",
        "for i in range(len(firstPredictions)):\n",
        "\n",
        "  a = np.append(firstPredictions[i], SecondPredictions[i])\n",
        "  pred.append(a)\n",
        "\n",
        "pred = np.array(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZKtvaC8e-BD"
      },
      "outputs": [],
      "source": [
        "print(f\"Predictions shape: {pred.shape} \")\n",
        "\n",
        "mean_squared_error = tfk.metrics.mean_squared_error(yTestA.flatten(), pred.flatten()).numpy()\n",
        "print(f\"Mean Squared Error: {mean_squared_error}\")\n",
        "\n",
        "mean_absolute_error = tfk.metrics.mean_absolute_error(yTestA.flatten(), pred.flatten()).numpy()\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "t02s5a0-qDws",
        "om8KoBQQqOWH",
        "_7JMt5Pyqbve",
        "z0zEm0jbqgfD",
        "zOIQGXXb5VQx",
        "-HJP9sgm2cXg",
        "TsTdN5KM7svg",
        "o505LKxmfpY0",
        "5ixM3_a_MGvy",
        "z4FXOL2PQeqv",
        "3Hoy1PuPZNOD",
        "-VeD-bnv1HJZ",
        "OoOpxO_Uqkc_"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}